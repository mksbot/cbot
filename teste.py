import requests
from bs4 import BeautifulSoup

from arquivos_texto import abrir_reg, registro

page = 'https://animefire.plus/home/2'
print(page)
hesders = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, como Gecko) '
                      'Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.51'}
site = requests.get(page, headers=hesders)
soup = BeautifulSoup(site.content, 'html.parser')
magnet2 = soup.find_all('div', class_='row ml-1 mr-1 mr-md-2')
i = 1
lista = []
for v in magnet2[0]:
    lista2 = []
    informaÃ§oes = str(v.text).replace('     ', '>')
    num = informaÃ§oes.find('- E')
    episodio = informaÃ§oes[num+1:informaÃ§oes.find('>', num)]
    nome = informaÃ§oes[:num].upper()
    if 'Dub' in nome or 'DUB' in nome or 'dub' in nome:
        mau_elementos = (
            "a,b,c,Ã§,Ã‡,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,"
            "Y,Z,Ã€,Ã,Ã‚,Ã„,Ã…,Ãƒ,Ã†,Ã‡,Ã‰,Ãˆ,ÃŠ,Ã‹,Ã,ÃŒ,ÃŽ,Ã,Ã‘,Ã“,Ã’,Ã”,Ã–,Ã˜,Ã•,O,E,Ãš,Ã™,Ã›,Ãœ,Ã,Y Ã ,Ã¡,Ã¢,Ã¤,Ã¥,Ã£,Ã¦,Ã§,Ã©,Ã¨,Ãª,Ã«,Ã­,Ã¬,Ã®,Ã¯,Ã±,Ã³,Ã²,"
            "Ã´,Ã¶,Ã¸,Ãµ,o,e,Ãº,Ã¹,Ã»,Ã¼,Ã½,y".replace(',', ' ').split())
        tag = ''
        for c in nome:
            if c not in mau_elementos:
                if tag == '':
                    tag = nome.replace(str(c), '_')
                else:
                    tag = tag.replace(str(c), '_')
        idioma = ' #DUB'
        descriÃ§ao = (f'{"_" * (len(nome) + 10)}\n\n'
                     f'     âœ…{nome}\n'
                     f'{"_" * (len(nome) + 10)}\n\n'
                     f'#{tag[:24].replace("__", "_")}..\n'
                     f'ðŸŽž{episodio}   |   '
                     f'ðŸ‡§ðŸ‡·{idioma}'
                     )
        print(descriÃ§ao)
        try:
            reg = abrir_reg('animes_dub')
        except:
            registro(f'{nome}{episodio}', 'animes_dub', 'nao')
            reg = abrir_reg('animes_dub')

        if str(nome + episodio) not in reg:
            lista2.append(descriÃ§ao)
            print(v)

            try:
                link = v.a['href']
                site = requests.get(link, headers=hesders)
                soup = BeautifulSoup(site.content, 'html.parser')
                magnet2 = soup.find_all('div', id='div_video',)
                for j in magnet2[0]:
                    try:
                        link2 = j.video['data-video-src']
                    except:
                        pass

                tratar_link = requests.get(link2)
                links = str(tratar_link.text)
                inicio = links.find('http', 150)
                fim = links.find('label', inicio)

                link3 = links[inicio:fim - 3].replace('\/', '/')
                print(link3)

                imagem = v.img['data-src']
                print(imagem)
                botao = quick_markup({

                    'ASSISTIR | BAIXAR': {'url': link3},

                }, row_width=2)
                lista2.append(botao)
                lista2.append(imagem)
                lista2.append(f'{nome + episodio}')
                lista.append(lista2)
                print(nome)
            except:
                    pass
        else:

            print('>> JA FOI ENVIADO !!')